{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'/root/.cache/kagglehub/datasets/mdmab0/audio-dataset/v1/some_folder/*.wav'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AJ9lOz5tzzDe",
        "outputId": "0fad7ecd-4f2f-4734-c674-bb4691e4dda7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/mdmab0/audio-dataset/v1/some_folder/*.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os # Import the 'os' module\n",
        "\n",
        "# Check if the directory is already mounted by looking for 'MyDrive'\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Google Drive is already mounted at /content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-vRlRfDz9Z-",
        "outputId": "79f3dd0b-4167-4195-9a9b-cb829c66590c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "import kagglehub # Importing kagglehub here to define 'path'\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mdmab0/audio-dataset\") # Defining 'path' before using it\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Source folder where audio files are stored\n",
        "source_folder = Path(path)\n",
        "\n",
        "# Destination in your Google Drive\n",
        "destination_folder = Path('/content/drive/MyDrive/audio_files')\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "destination_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy .wav files\n",
        "for file in source_folder.rglob(\"*.wav\"):\n",
        "    shutil.copy(file, destination_folder)\n",
        "\n",
        "print(f\"Copied all .wav files to: {destination_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrULMxZhzer_",
        "outputId": "b6e0d990-5b4a-4ea5-9916-0751c5ecb8cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/audio-dataset\n",
            "Copied all .wav files to: /content/drive/MyDrive/audio_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, file in enumerate(source_folder.rglob(\"*.wav\")):\n",
        "    new_name = f\"audio_{i:04d}.wav\"\n",
        "    shutil.copy(file, destination_folder / new_name)\n"
      ],
      "metadata": {
        "id": "UAR9a_oV0NG6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa matplotlib soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vf4K29k044Q",
        "outputId": "465448cb-c66d-47d6-893d-730e19326d70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "PgEQUUl1086e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Source and destination folders\n",
        "source_folder = Path(\"/content/drive/MyDrive/audio_files\")\n",
        "output_folder = Path(\"/content/drive/MyDrive/audio_processed\")\n",
        "output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Function to save waveform, spectrogram, and MFCC\n",
        "def process_audio(file_path, save_folder):\n",
        "    filename = Path(file_path).stem\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Waveform\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    librosa.display.waveshow(audio, sr=sr)\n",
        "    plt.title(f'Waveform - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_waveform.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Spectrogram\n",
        "    spec = librosa.stft(audio)\n",
        "    spec_db = librosa.amplitude_to_db(abs(spec))\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(spec_db, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(f'Spectrogram - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_spectrogram.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mfcc, x_axis='time')\n",
        "    plt.colorbar()\n",
        "    plt.title(f'MFCC - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_mfcc.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Processed: {filename}\")\n",
        "\n",
        "# Limit to 500 files\n",
        "max_files = 200\n",
        "count = 0\n",
        "\n",
        "for wav_file in source_folder.rglob(\"*.wav\"):\n",
        "    if count >= max_files:\n",
        "        break\n",
        "    process_audio(wav_file, output_folder)\n",
        "    count += 1\n",
        "\n",
        "print(f\"✅ Processed {count} audio files and saved results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi2_1f860_wA",
        "outputId": "fc29f7fe-28f6-4cda-ed51-6fd55c428b79"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: not_hs_phrase_308\n",
            "Processed: hs_audio_15_22_f\n",
            "Processed: hs_audio_word_15_10\n",
            "Processed: hs_audio_word_1_3_f\n",
            "Processed: hs_audio_4_1\n",
            "Processed: hs_audio_word_24_2\n",
            "Processed: hs_audio_word_5_5\n",
            "Processed: hs_audio_word_9_7\n",
            "Processed: not_hs_phrase_107\n",
            "Processed: not_hs_phrase_442\n",
            "Processed: not_hs_phrase_105\n",
            "Processed: hs_audio_5_23\n",
            "Processed: not_hs_phrase_178\n",
            "Processed: not_hs_phrase_479\n",
            "Processed: not_hs_phrase_230_f\n",
            "Processed: not_hs_phrase_545\n",
            "Processed: not_hs_phrase_384_f\n",
            "Processed: hs_audio_15_27_f\n",
            "Processed: not_hs_phrase_348_f\n",
            "Processed: hs_audio_word_26_17\n",
            "Processed: not_hs_audio_8_8\n",
            "Processed: not_hs_audio_8_10\n",
            "Processed: hs_audio_word_30_11\n",
            "Processed: not_hs_phrase_452\n",
            "Processed: hs_audio_5_14\n",
            "Processed: hs_audio_word_29_16\n",
            "Processed: hs_audio_word_6_6\n",
            "Processed: not_hs_phrase_529\n",
            "Processed: hs_audio_14_11\n",
            "Processed: not_hs_phrase_464\n",
            "Processed: not_hs_phrase_343\n",
            "Processed: hs_audio_5_41\n",
            "Processed: hs_audio_word_20_8\n",
            "Processed: not_hs_audio_8_12\n",
            "Processed: hs_audio_word_23_9\n",
            "Processed: not_hs_phrase_549\n",
            "Processed: not_hs_phrase_65\n",
            "Processed: hs_audio_word_23_1\n",
            "Processed: not_hs_phrase_307\n",
            "Processed: hs_audio_15_12_f\n",
            "Processed: hs_audio_word_12_3\n",
            "Processed: not_hs_phrase_289_f\n",
            "Processed: not_hs_phrase_388\n",
            "Processed: not_hs_phrase_411\n",
            "Processed: hs_audio_word_16_14\n",
            "Processed: not_hs_audio_8_13\n",
            "Processed: not_hs_phrase_44_f\n",
            "Processed: not_hs_phrase_494_f\n",
            "Processed: hs_audio_word_18_7_f\n",
            "Processed: not_hs_phrase_83\n",
            "Processed: not_hs_phrase_100\n",
            "Processed: hs_audio_15_8_f\n",
            "Processed: not_hs_phrase_283\n",
            "Processed: not_hs_phrase_419\n",
            "Processed: hs_audio_15_13_f\n",
            "Processed: hs_audio_word_13_5_f\n",
            "Processed: not_hs_phrase_75_f\n",
            "Processed: hs_audio_word_17_5\n",
            "Processed: not_hs_phrase_297_f\n",
            "Processed: hs_audio_word_24_5\n",
            "Processed: hs_audio_word_30_13\n",
            "Processed: hs_audio_word_32_8\n",
            "Processed: not_hs_phrase_72\n",
            "Processed: hs_audio_5_47\n",
            "Processed: hs_audio_word_15_5\n",
            "Processed: not_hs_phrase_302_f\n",
            "Processed: not_hs_phrase_295\n",
            "Processed: not_hs_audio_8_32\n",
            "Processed: hs_audio_15_4_f\n",
            "Processed: hs_audio_word_24_15\n",
            "Processed: hs_audio_word_9_6\n",
            "Processed: not_hs_phrase_181\n",
            "Processed: hs_audio_word_27_5\n",
            "Processed: not_hs_phrase_130_f\n",
            "Processed: not_hs_phrase_101_f\n",
            "Processed: hs_audio_9_12\n",
            "Processed: not_hs_phrase_407\n",
            "Processed: not_hs_phrase_30_f\n",
            "Processed: not_hs_phrase_410\n",
            "Processed: hs_audio_word_11_11_f\n",
            "Processed: hs_audio_14_16\n",
            "Processed: hs_audio_14_27\n",
            "Processed: hs_audio_word_28_3_f\n",
            "Processed: not_hs_phrase_469\n",
            "Processed: not_hs_phrase_296_f\n",
            "Processed: hs_audio_10_5\n",
            "Processed: hs_audio_word_13_13\n",
            "Processed: not_hs_phrase_320\n",
            "Processed: hs_audio_word_16_6_f\n",
            "Processed: hs_audio_11_25\n",
            "Processed: hs_audio_12_2\n",
            "Processed: hs_audio_word_24_9_f\n",
            "Processed: hs_audio_word_29_14_f\n",
            "Processed: not_hs_phrase_191\n",
            "Processed: not_hs_phrase_424\n",
            "Processed: not_hs_audio_8_20\n",
            "Processed: not_hs_phrase_597_f\n",
            "Processed: hs_audio_11_15\n",
            "Processed: not_hs_phrase_12\n",
            "Processed: not_hs_phrase_209_f\n",
            "Processed: not_hs_phrase_429\n",
            "Processed: not_hs_phrase_366\n",
            "Processed: not_hs_phrase_539\n",
            "Processed: hs_audio_word_30_9\n",
            "Processed: hs_audio_9_10\n",
            "Processed: not_hs_phrase_119\n",
            "Processed: hs_audio_word_29_18\n",
            "Processed: hs_audio_5_4\n",
            "Processed: hs_audio_word_32_13\n",
            "Processed: hs_audio_word_24_14\n",
            "Processed: hs_audio_11_2\n",
            "Processed: hs_audio_word_26_15\n",
            "Processed: hs_audio_word_24_26_f\n",
            "Processed: hs_audio_5_53\n",
            "Processed: hs_audio_15_26_f\n",
            "Processed: hs_audio_15_2_f\n",
            "Processed: hs_audio_word_24_25\n",
            "Processed: hs_audio_word_31_2\n",
            "Processed: not_hs_phrase_74_f\n",
            "Processed: hs_audio_5_50\n",
            "Processed: not_hs_phrase_352\n",
            "Processed: hs_audio_11_10\n",
            "Processed: hs_audio_15_28_f\n",
            "Processed: hs_audio_word_22_3_f\n",
            "Processed: hs_audio_word_28_4_f\n",
            "Processed: not_hs_phrase_364_f\n",
            "Processed: hs_audio_word_26_19\n",
            "Processed: hs_audio_8_4\n",
            "Processed: not_hs_phrase_212\n",
            "Processed: not_hs_phrase_241_f\n",
            "Processed: not_hs_phrase_86\n",
            "Processed: not_hs_phrase_288_f\n",
            "Processed: not_hs_phrase_595_f\n",
            "Processed: hs_audio_word_26_16\n",
            "Processed: hs_audio_word_24_16_f\n",
            "Processed: hs_audio_word_10_4_f\n",
            "Processed: not_hs_phrase_129_f\n",
            "Processed: hs_audio_5_017\n",
            "Processed: hs_audio_word_31_6\n",
            "Processed: hs_audio_word_11_4_f\n",
            "Processed: hs_audio_word_24_21\n",
            "Processed: not_hs_phrase_406_f\n",
            "Processed: hs_audio_word_4_1_f\n",
            "Processed: not_hs_phrase_589\n",
            "Processed: not_hs_phrase_91_f\n",
            "Processed: not_hs_phrase_358\n",
            "Processed: not_hs_phrase_331\n",
            "Processed: hs_audio_word_14_3\n",
            "Processed: hs_audio_word_10_9\n",
            "Processed: not_hs_phrase_505\n",
            "Processed: hs_audio_word_23_11\n",
            "Processed: not_hs_phrase_351\n",
            "Processed: hs_audio_word_11_3\n",
            "Processed: not_hs_phrase_73\n",
            "Processed: hs_audio_word_31_15_f\n",
            "Processed: hs_audio_word_25_6_f\n",
            "Processed: hs_audio_word_22_8\n",
            "Processed: hs_audio_word_14_5_f\n",
            "Processed: hs_audio_word_20_7\n",
            "Processed: not_hs_phrase_232\n",
            "Processed: not_hs_phrase_193\n",
            "Processed: hs_audio_word_16_3\n",
            "Processed: not_hs_phrase_422\n",
            "Processed: not_hs_phrase_425\n",
            "Processed: not_hs_phrase_432_f\n",
            "Processed: not_hs_phrase_199\n",
            "Processed: hs_audio_word_3_3_f\n",
            "Processed: hs_audio_word_32_14_f\n",
            "Processed: not_hs_phrase_346\n",
            "Processed: hs_audio_10_6\n",
            "Processed: not_hs_phrase_337_f\n",
            "Processed: not_hs_phrase_110_f\n",
            "Processed: hs_audio_word_14_10\n",
            "Processed: hs_audio_word_16_1\n",
            "Processed: not_hs_phrase_476\n",
            "Processed: not_hs_phrase_147\n",
            "Processed: not_hs_phrase_24\n",
            "Processed: not_hs_phrase_280\n",
            "Processed: hs_audio_word_1_8\n",
            "Processed: not_hs_phrase_176_f\n",
            "Processed: not_hs_phrase_399\n",
            "Processed: not_hs_phrase_412_f\n",
            "Processed: not_hs_phrase_332\n",
            "Processed: not_hs_phrase_174\n",
            "Processed: hs_audio_5_16\n",
            "Processed: not_hs_phrase_510\n",
            "Processed: not_hs_phrase_259\n",
            "Processed: not_hs_phrase_70\n",
            "Processed: not_hs_phrase_437_f\n",
            "Processed: hs_audio_word_2_2_f\n",
            "Processed: not_hs_phrase_218_f\n",
            "Processed: not_hs_phrase_150_f\n",
            "Processed: hs_audio_word_24_6_f\n",
            "Processed: not_hs_phrase_550\n",
            "Processed: not_hs_phrase_439\n",
            "Processed: hs_audio_word_4_2\n",
            "Processed: hs_audio_word_30_14_f\n",
            "Processed: not_hs_phrase_475\n",
            "Processed: hs_audio_4_15\n",
            "Processed: hs_audio_word_30_4_f\n",
            "✅ Processed 200 audio files and saved results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "OzU8LUec1bBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c35738-903a-4b59-f78d-cc048def76a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "data_path = Path(\"/content/drive/MyDrive/audio_files\")\n",
        "all_files = list(data_path.glob(\"*.wav\"))[:200]  # Limit to 200 for training\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "max_len = 100\n",
        "n_mfcc = 40\n",
        "\n",
        "for file_path in all_files:\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc).T\n",
        "\n",
        "    if mfcc.shape[0] >= max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        pad = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad), (0, 0)), mode='constant')\n",
        "\n",
        "    X.append(mfcc)\n",
        "    y.append(0)  # Default label (binary or dummy for now)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ Loaded MFCC features from\", len(X), \"files\")\n",
        "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_xh6WmgEz2j",
        "outputId": "e0d7cc09-921d-42e7-868e-c81c950f5279"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded MFCC features from 200 files\n",
            "X shape: (200, 100, 40) | y shape: (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape input to match LSTM [samples, time steps, features]\n",
        "# Already in (samples, 100, 40)\n",
        "\n",
        "# 2. Build the LSTM model\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(X.shape[1], X.shape[2])),  # Mask padded time steps\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the model\n",
        "history = model.fit(X_train, y_train, epochs=15, batch_size=16,\n",
        "                    validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# 5. Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"\\n✅ Test Accuracy: {acc:.4f} | Test Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYHUffB1FMZN",
        "outputId": "0e95f81f-b45a-431b-b48e-dc3dc505a30a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.7639 - loss: 0.5485 - val_accuracy: 1.0000 - val_loss: 0.1756\n",
            "Epoch 2/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1370 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
            "Epoch 3/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
            "Epoch 4/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 5/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 6/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 7/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 8.2101e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 6.5470e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.1433e-04 - val_accuracy: 1.0000 - val_loss: 5.3824e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 8.4348e-04 - val_accuracy: 1.0000 - val_loss: 4.5658e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 7.0568e-04 - val_accuracy: 1.0000 - val_loss: 3.9557e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 6.4122e-04 - val_accuracy: 1.0000 - val_loss: 3.4618e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.6111e-04 - val_accuracy: 1.0000 - val_loss: 3.0428e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.4498e-04 - val_accuracy: 1.0000 - val_loss: 2.7183e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.9956e-04 - val_accuracy: 1.0000 - val_loss: 2.4446e-04\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.4407e-04\n",
            "\n",
            "✅ Test Accuracy: 1.0000 | Test Loss: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "# Convert probabilities to binary class labels (threshold = 0.5)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Flatten arrays\n",
        "y_pred = y_pred.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"🧩 Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ9BIHW6FoKB",
        "outputId": "06cb3668-d43c-4675-fbc3-b99e3b6499e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        40\n",
            "\n",
            "    accuracy                         1.0000        40\n",
            "   macro avg     1.0000    1.0000    1.0000        40\n",
            "weighted avg     1.0000    1.0000    1.0000        40\n",
            "\n",
            "🧩 Confusion Matrix:\n",
            "[[40]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Load MFCC features\n",
        "data_path = Path(\"/content/drive/MyDrive/audio_files\")\n",
        "all_files = list(data_path.glob(\"*.wav\"))[:200]  # Limit to 200 files\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "max_len = 100\n",
        "n_mfcc = 40\n",
        "\n",
        "for file_path in all_files:\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc).T\n",
        "\n",
        "    if mfcc.shape[0] >= max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        pad = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad), (0, 0)), mode='constant')\n",
        "\n",
        "    X.append(mfcc)\n",
        "    y.append(0 if '0' in file_path.stem else 1)  # Example label logic\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"✅ Loaded MFCCs: {X.shape}, Labels: {np.unique(y, return_counts=True)}\")\n",
        "\n",
        "# Step 2: K-Fold Cross Validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "all_reports = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=(X.shape[1], X.shape[2])),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(X_val)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "    report = classification_report(y_val, y_pred, digits=4, output_dict=True)\n",
        "    all_reports.append(report)\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val, y_pred, digits=4))\n",
        "\n",
        "# Step 3: Average Metrics\n",
        "avg_acc = np.mean([r.get('accuracy', 0) for r in all_reports])\n",
        "avg_prec_0 = np.mean([r.get('0', {}).get('precision', 0) for r in all_reports])\n",
        "avg_prec_1 = np.mean([r.get('1', {}).get('precision', 0) for r in all_reports])\n",
        "avg_recall_0 = np.mean([r.get('0', {}).get('recall', 0) for r in all_reports])\n",
        "avg_recall_1 = np.mean([r.get('1', {}).get('recall', 0) for r in all_reports])\n",
        "\n",
        "print(\"\\n📊 Average Scores Across Folds:\")\n",
        "print(f\"Avg Accuracy       : {avg_acc:.4f}\")\n",
        "print(f\"Avg Precision [0/1]: {avg_prec_0:.4f} / {avg_prec_1:.4f}\")\n",
        "print(f\"Avg Recall    [0/1]: {avg_recall_0:.4f} / {avg_recall_1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZRXjPhzF9WL",
        "outputId": "7855079f-b0d6-4969-ce78-a37ba3dd8d2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded MFCCs: (200, 100, 40), Labels: (array([0, 1]), array([ 41, 159]))\n",
            "\n",
            "📂 Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0  9]\n",
            " [ 2 29]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000         9\n",
            "           1     0.7632    0.9355    0.8406        31\n",
            "\n",
            "    accuracy                         0.7250        40\n",
            "   macro avg     0.3816    0.4677    0.4203        40\n",
            "weighted avg     0.5914    0.7250    0.6514        40\n",
            "\n",
            "\n",
            "📂 Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0  8]\n",
            " [ 2 30]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000         8\n",
            "           1     0.7895    0.9375    0.8571        32\n",
            "\n",
            "    accuracy                         0.7500        40\n",
            "   macro avg     0.3947    0.4688    0.4286        40\n",
            "weighted avg     0.6316    0.7500    0.6857        40\n",
            "\n",
            "\n",
            "📂 Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0  8]\n",
            " [ 4 28]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000         8\n",
            "           1     0.7778    0.8750    0.8235        32\n",
            "\n",
            "    accuracy                         0.7000        40\n",
            "   macro avg     0.3889    0.4375    0.4118        40\n",
            "weighted avg     0.6222    0.7000    0.6588        40\n",
            "\n",
            "\n",
            "📂 Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0  8]\n",
            " [ 5 27]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000         8\n",
            "           1     0.7714    0.8438    0.8060        32\n",
            "\n",
            "    accuracy                         0.6750        40\n",
            "   macro avg     0.3857    0.4219    0.4030        40\n",
            "weighted avg     0.6171    0.6750    0.6448        40\n",
            "\n",
            "\n",
            "📂 Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n",
            "Confusion Matrix:\n",
            "[[ 3  5]\n",
            " [10 22]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2308    0.3750    0.2857         8\n",
            "           1     0.8148    0.6875    0.7458        32\n",
            "\n",
            "    accuracy                         0.6250        40\n",
            "   macro avg     0.5228    0.5312    0.5157        40\n",
            "weighted avg     0.6980    0.6250    0.6538        40\n",
            "\n",
            "\n",
            "📊 Average Scores Across Folds:\n",
            "Avg Accuracy       : 0.6950\n",
            "Avg Precision [0/1]: 0.0462 / 0.7833\n",
            "Avg Recall    [0/1]: 0.0750 / 0.8558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict\n",
        "y_pred_probs = model.predict(X_val)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Print numeric confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Confusion Matrix - Fold {fold+1}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "kYfeFvGIGy6_",
        "outputId": "07591f8e-7270-4dc5-9d15-05f6e36dcc7b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Confusion Matrix:\n",
            "[[ 3  5]\n",
            " [10 22]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_pred_probs = model.predict(X_val).flatten()\n",
        "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Split predicted probs by true labels\n",
        "group0 = y_pred_probs[y_val == 0]\n",
        "group1 = y_pred_probs[y_val == 1]\n",
        "\n",
        "# --- Z-Test ---\n",
        "# Calculate proportions\n",
        "n0, n1 = len(group0), len(group1)\n",
        "p0, p1 = np.mean(y_pred_labels[y_val == 0]), np.mean(y_pred_labels[y_val == 1])\n",
        "\n",
        "pooled_p = (p0 * n0 + p1 * n1) / (n0 + n1)\n",
        "z = (p0 - p1) / np.sqrt(pooled_p * (1 - pooled_p) * (1/n0 + 1/n1))\n",
        "p_value_z = stats.norm.sf(abs(z)) * 2\n",
        "\n",
        "print(f\"\\n🧪 Z-Test: Z = {z:.4f}, p = {p_value_z:.4f}\")\n",
        "\n",
        "# --- T-Test ---\n",
        "t_stat, p_value_t = stats.ttest_ind(group0, group1)\n",
        "print(f\"🧪 T-Test: t = {t_stat:.4f}, p = {p_value_t:.4f}\")\n",
        "\n",
        "# --- Optional: ANOVA ---\n",
        "f_stat, p_value_anova = stats.f_oneway(group0, group1)\n",
        "print(f\"🧪 ANOVA: F = {f_stat:.4f}, p = {p_value_anova:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9mEwY8kEG_NM",
        "outputId": "73ec9065-9e75-4b55-ae12-b27c30f9f1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "🧪 Z-Test: Z = -0.3376, p = 0.7357\n",
            "🧪 T-Test: t = -0.2457, p = 0.8072\n",
            "🧪 ANOVA: F = 0.0604, p = 0.8072\n"
          ]
        }
      ]
    }
  ]
}